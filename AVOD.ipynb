{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c219c1",
   "metadata": {},
   "source": [
    "- [Wasserstien](https://github.com/AhmedYousriSobhi/W-Stereo-Disp) --> input: Left/Right image + Calib , output : Depthmap | Fork\n",
    "- [PsuedoLidar_V2](https://github.com/mileyan/Pseudo_Lidar_V2) --> input Depthmap , output : points clouds + Planes.\n",
    "- [Avod](https://github.com/AhmedYousriSobhi/avod) --> input: Images + points clouds + planes + calib , output : labels.\n",
    "- [Kitti Visiualize](https://github.com/kuixu/kitti_object_vis) --> input: labels converted + image_2 + calib+ point clouds , output: BEV\n",
    "\n",
    "\n",
    "covert from avod format to kitti :\n",
    "https://github.com/kujason/avod/wiki/Data-Formats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bbde3e6-9379-4870-ac1f-c8080cc19e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodule path 'wavedata': checked out 'c4b5aabd9eb3b74fad777349f75161032d3460fa'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'avod'...\n",
      "Submodule 'wavedata' (git@github.com:kujason/wavedata.git) registered for path 'wavedata'\n",
      "Cloning into 'Z:/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/avod/wavedata'...\n"
     ]
    }
   ],
   "source": [
    " !git clone git@github.com:kujason/avod.git --recurse-submodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ea0392-90f2-4c84-8705-9476df70153c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup\n"
     ]
    }
   ],
   "source": [
    "%cd /media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812173ef-36c2-4260-875a-9c051338adb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ff98652-f551-4c02-a5a5-bc9a87032849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/yousri/.local/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.13.0 in /home/yousri/.local/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.21.2)\n",
      "Requirement already satisfied: opencv-python in /home/yousri/.local/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (4.5.4.60)\n",
      "Requirement already satisfied: pandas in /home/yousri/.local/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.3.4)\n",
      "Requirement already satisfied: pillow in /home/yousri/.local/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (8.4.0)\n",
      "Collecting protobuf==3.12.2\n",
      "  Downloading protobuf-3.12.2-cp38-cp38-manylinux1_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 321 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/yousri/.local/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.4.1)\n",
      "Requirement already satisfied: sklearn in /home/yousri/.local/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (0.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/yousri/.local/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib->-r requirements.txt (line 1)) (2.7.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/yousri/.local/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/yousri/.local/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas->-r requirements.txt (line 4)) (2019.3)\n",
      "Requirement already satisfied: six>=1.9 in /usr/lib/python3/dist-packages (from protobuf==3.12.2->-r requirements.txt (line 6)) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from protobuf==3.12.2->-r requirements.txt (line 6)) (45.2.0)\n",
      "Requirement already satisfied: scikit-learn in /home/yousri/.local/lib/python3.8/site-packages (from sklearn->-r requirements.txt (line 8)) (1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/yousri/.local/lib/python3.8/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/yousri/.local/lib/python3.8/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 8)) (3.0.0)\n",
      "\u001b[31mERROR: tensorflow-metadata 1.4.0 has requirement absl-py<0.13,>=0.9, but you'll have absl-py 1.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-metadata 1.4.0 has requirement protobuf<4,>=3.13, but you'll have protobuf 3.12.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.2.0\n",
      "    Uninstalling protobuf-3.2.0:\n",
      "      Successfully uninstalled protobuf-3.2.0\n",
      "Successfully installed protobuf-3.12.2\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-gpu==1.3.0 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0, 2.5.1, 2.5.2, 2.6.0, 2.6.1, 2.6.2, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.8.0rc0)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow-gpu==1.3.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%cd avod\n",
    "!pip3 install -r requirements.txt\n",
    "!pip3 install tensorflow-gpu==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf28b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For nonvirtualenv users\n",
    "!export PYTHONPATH=$PYTHONPATH:'/path/to/avod'\n",
    "!export PYTHONPATH=$PYTHONPATH:'/path/to/avod/wavedata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1539bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 9.3.0\n",
      "-- The CXX compiler identification is GNU 9.3.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod/wavedata/wavedata/tools/core/lib\n",
      "\u001b[35m\u001b[1mScanning dependencies of target integral_images_3d\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/integral_images_3d.dir/integral_images_3d.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared library libintegral_images_3d.so\u001b[0m\n",
      "[100%] Built target integral_images_3d\n"
     ]
    }
   ],
   "source": [
    "!sh ./scripts/install/build_integral_image_lib.bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ac1cc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36a18575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling protos in /media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod/avod/protos\r\n",
      "[libprotobuf WARNING google/protobuf/compiler/parser.cc:562] No syntax specified for the proto file: avod/protos/kitti_dataset.proto. Please use 'syntax = \"proto2\";' or 'syntax = \"proto3\";' to specify a syntax version. (Defaulted to proto2 syntax.)\r\n",
      "[libprotobuf WARNING google/protobuf/compiler/parser.cc:562] No syntax specified for the proto file: avod/protos/kitti_utils.proto. Please use 'syntax = \"proto2\";' or 'syntax = \"proto3\";' to specify a syntax version. (Defaulted to proto2 syntax.)\r\n",
      "[libprotobuf WARNING google/protobuf/compiler/parser.cc:562] No syntax specified for the proto file: avod/protos/mini_batch.proto. Please use 'syntax = \"proto2\";' or 'syntax = \"proto3\";' to specify a syntax version. (Defaulted to proto2 syntax.)\r\n",
      "[libprotobuf WARNING google/protobuf/compiler/parser.cc:562] No syntax specified for the proto file: avod/protos/layers.proto. Please use 'syntax = \"proto2\";' or 'syntax = \"proto3\";' to specify a syntax version. (Defaulted to proto2 syntax.)\r\n",
      "[libprotobuf WARNING google/protobuf/compiler/parser.cc:562] No syntax specified for the proto file: avod/protos/model.proto. Please use 'syntax = \"proto2\";' or 'syntax = \"proto3\";' to specify a syntax version. (Defaulted to proto2 syntax.)\r\n",
      "[libprotobuf WARNING google/protobuf/compiler/parser.cc:562] No syntax specified for the proto file: avod/protos/pipeline.proto. Please use 'syntax = \"proto2\";' or 'syntax = \"proto3\";' to specify a syntax version. (Defaulted to proto2 syntax.)\r\n",
      "Done\r\n"
     ]
    }
   ],
   "source": [
    "!sh avod/protos/run_protoc.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08fac83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod\n"
     ]
    }
   ],
   "source": [
    "%cd backup/avod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ded61",
   "metadata": {},
   "source": [
    "# Steps:\n",
    "File: avod/avod/data/outputs/pyramid_cars_with_aug_example.config \n",
    "- in Line 136 - dataset_dir =  change your dataset location.\n",
    "- in Line 137 - data_split = name of split txt file.\n",
    "- in Line 139 - data_split_dir = \"\" -- Empty string.\n",
    "\n",
    "File: avod/avod/datasets/kitti/kitti_dataset.py - in Line 76\n",
    "- possible_splits = ['val']\n",
    "- import sys\n",
    "- sys.path.insert(1, 'PATH_TO_LOCATION/avod/wavedata')\n",
    "\n",
    "File: avod/avod/core/evaluator.py - line 373:\n",
    "- checkpoint_to_restore = 'PATH_TO_LOCATION/avod/avod/data/outputs/pyramid_cars_with_aug_example/checkpoints/pyramid_cars_with_aug_example_scratch_300_val-00120000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d15bd38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-26 17:07:05.932585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-26 17:07:05.956962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-26 17:07:05.957170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name: \"kitti\"\n",
      "dataset_dir: \"/media/yousri/Kingdom/Workspace/ITi/Tekomoro/Kitti Datasets/Sample\"\n",
      "data_split: \"val\"\n",
      "data_split_dir: \"\"\n",
      "has_labels: false\n",
      "cluster_split: \"val\"\n",
      "classes: \"Car\"\n",
      "num_clusters: 2\n",
      "bev_source: \"lidar\"\n",
      "aug_list: \"flipping\"\n",
      "aug_list: \"pca_jitter\"\n",
      "kitti_utils_config {\n",
      "  area_extents: -40.0\n",
      "  area_extents: 40.0\n",
      "  area_extents: -5.0\n",
      "  area_extents: 3.0\n",
      "  area_extents: 0.0\n",
      "  area_extents: 70.0\n",
      "  voxel_size: 0.10000000149011612\n",
      "  anchor_strides: 0.5\n",
      "  anchor_strides: 0.5\n",
      "  density_threshold: 1\n",
      "  bev_generator {\n",
      "    slices {\n",
      "      height_lo: -0.20000000298023224\n",
      "      height_hi: 2.299999952316284\n",
      "      num_slices: 5\n",
      "    }\n",
      "  }\n",
      "  mini_batch_config {\n",
      "    density_threshold: 1\n",
      "    rpn_config {\n",
      "      iou_2d_thresholds {\n",
      "        neg_iou_lo: 0.0\n",
      "        neg_iou_hi: 0.30000001192092896\n",
      "        pos_iou_lo: 0.5\n",
      "        pos_iou_hi: 1.0\n",
      "      }\n",
      "      mini_batch_size: 512\n",
      "    }\n",
      "    avod_config {\n",
      "      iou_2d_thresholds {\n",
      "        neg_iou_lo: 0.0\n",
      "        neg_iou_hi: 0.550000011920929\n",
      "        pos_iou_lo: 0.6499999761581421\n",
      "        pos_iou_hi: 1.0\n",
      "      }\n",
      "      mini_batch_size: 1024\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/media/yousri/Kingdom/Workspace/ITi/Tekomoro/Kitti Datasets/Sample/training\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2021-12-26 17:07:05.966909: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-26 17:07:05.967756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-26 17:07:05.967979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-26 17:07:05.968121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-26 17:07:06.322085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-26 17:07:06.322263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-26 17:07:06.322384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-26 17:07:06.322494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4323 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING:tensorflow:From /media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod/avod/core/feature_extractors/img_feature_extractor.py:29: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1226 17:07:06.328555 140032506435392 deprecation.py:341] From /media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod/avod/core/feature_extractors/img_feature_extractor.py:29: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "/home/yousri/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "WARNING:tensorflow:From /home/yousri/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W1226 17:07:07.131396 140032506435392 deprecation.py:545] From /home/yousri/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod/avod/core/ops.py:32: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1226 17:07:07.287407 140032506435392 deprecation.py:341] From /media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod/avod/core/ops.py:32: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "/home/yousri/.local/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:336: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "WARNING:tensorflow:From /home/yousri/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096: calling reduce_min_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1226 17:07:07.782641 140032506435392 deprecation.py:545] From /home/yousri/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096: calling reduce_min_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/yousri/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1226 17:07:07.783551 140032506435392 deprecation.py:545] From /home/yousri/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "No checkpoints found\n",
      "INFO:tensorflow:Restoring parameters from /media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod/avod/data/outputs/pyramid_cars_with_aug_example/checkpoints/pyramid_cars_with_aug_example_scratch_300_val-00120000\n",
      "I1226 17:07:07.944856 140032506435392 saver.py:1399] Restoring parameters from /media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod/avod/data/outputs/pyramid_cars_with_aug_example/checkpoints/pyramid_cars_with_aug_example_scratch_300_val-00120000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 12  16  19]\n",
      "  [ 11  20  21]\n",
      "  [  9  23  30]\n",
      "  ...\n",
      "  [  9   7   4]\n",
      "  [  9  10   6]\n",
      "  [  8  12  10]]\n",
      "\n",
      " [[ 11  15  18]\n",
      "  [ 12  16  17]\n",
      "  [ 11  17  24]\n",
      "  ...\n",
      "  [  9   8   5]\n",
      "  [  9  10   6]\n",
      "  [  9  11   7]]\n",
      "\n",
      " [[ 11  17  28]\n",
      "  [ 11  20  28]\n",
      "  [ 12  23  22]\n",
      "  ...\n",
      "  [ 10  10   5]\n",
      "  [ 10  10   6]\n",
      "  [ 10  11   9]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 11  18 105]\n",
      "  [ 11  17 104]\n",
      "  [ 11  17 103]\n",
      "  ...\n",
      "  [ 33  25  41]\n",
      "  [ 35  24  50]\n",
      "  [ 32  24  60]]\n",
      "\n",
      " [[  9  16 103]\n",
      "  [ 11  16 104]\n",
      "  [ 11  16 103]\n",
      "  ...\n",
      "  [ 14  16  37]\n",
      "  [ 16  17  35]\n",
      "  [ 18  17  30]]\n",
      "\n",
      " [[  9  16 106]\n",
      "  [ 11  17 106]\n",
      "  [ 11  17 102]\n",
      "  ...\n",
      "  [ 15  14  17]\n",
      "  [ 14  14  18]\n",
      "  [ 14  13  20]]]\n",
      "Step 120000: 1 / 1, Inference on sample 000008\n",
      "2021-12-26 17:07:09.069717: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8300\n",
      "2021-12-26 17:07:09.501343: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-12-26 17:07:10.167753: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.72GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-26 17:07:10.167807: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.72GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "Feed dict time:\n",
      "Min:  0.10953\n",
      "Max:  0.10953\n",
      "Mean:  0.10953\n",
      "Median:  0.10953\n",
      "Inference time:\n",
      "Min:  4.0734\n",
      "Max:  4.0734\n",
      "Mean:  4.0734\n",
      "Median:  4.0734\n",
      "Step 120000: Finished evaluation, results saved to /media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod/avod/data/outputs/pyramid_cars_with_aug_example/predictions/proposals_and_scores/val/120000\n"
     ]
    }
   ],
   "source": [
    "!python3 avod/experiments/run_inference.py --checkpoint_name='pyramid_cars_with_aug_example' --data_split='val' --ckpt_indices=120 --device='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c8ba178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "/home/yousri/Kitti/object/training\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Available steps: ['120000']\n",
      "Prediction images saved to: /media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod/avod/data/outputs/pyramid_cars_with_aug_example/predictions/images_2d/predictions/val/120000/0.1\n",
      "Saving 1 / 1, Avg Time: 1.000s, Time Remaining: 1.00s\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!python3 demos/show_predictions_2d.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9013dd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "/home/yousri/Kitti/object/training\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "=== Showing BEV maps for image: 000000.png ===\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"demos/kitti_bev_vis.py\", line 175, in <module>\r\n",
      "    main()\r\n",
      "  File \"demos/kitti_bev_vis.py\", line 110, in main\r\n",
      "    point_cloud = kitti_utils.get_point_cloud(\r\n",
      "  File \"/media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod/avod/datasets/kitti/kitti_utils.py\", line 155, in get_point_cloud\r\n",
      "    point_cloud = obj_utils.get_lidar_point_cloud(\r\n",
      "  File \"/media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod/wavedata/wavedata/tools/obj_detection/obj_utils.py\", line 236, in get_lidar_point_cloud\r\n",
      "    frame_calib = calib_utils.read_calibration(calib_dir, img_idx)\r\n",
      "  File \"/media/yousri/Kingdom/Workspace/ITi/WorkSpace/Python Notebooks/Jupyter/Tekomoro/Wasserstein_Distances_Paper/backup/avod/wavedata/wavedata/tools/core/calib_utils.py\", line 77, in read_calibration\r\n",
      "    data_file = open(calib_dir + \"/%06d.txt\" % img_idx, 'r')\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/yousri/Kitti/object/training/calib/000000.txt'\r\n"
     ]
    }
   ],
   "source": [
    "!python3 demos/kitti_bev_vis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38724402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
